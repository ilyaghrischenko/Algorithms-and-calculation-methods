{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "04.11.23, © Hryshchenko Illya, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторна робота №4. Алгоритми пошуку. Стратегія \"грубої сили\". (short version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Мета:__ _Засвоїти варіанти реалізації алгоритмів пошуку засобами Python і методи оцінки їх складності._ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лінійний пошук. Стратегія \"грубої сили\"\n",
    "\n",
    "Одним з найпростіших алгоритмів пошуку є [_лінійний пошук_](https://uk.wikipedia.org/wiki/%D0%9B%D1%96%D0%BD%D1%96%D0%B9%D0%BD%D0%B8%D0%B9_%D0%BF%D0%BE%D1%88%D1%83%D0%BA). Сенс алгоритму полягає в тому, що пошук починають з першого елементу масива. Якщо поточний елемент списку не дорівнює шуканому значенню, то здійснюється перехід до наступного елементу. Таким чином, у результаті кожної перевірки область пошуку зменшується на один елемент.  \n",
    "\n",
    "Лінійний пошук також відомий, як _метод перебору_ або \"грубої сили\". Працює за час $O(n)$, де $n$ -- довжина списку на вході."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Завдання на самостійну роботу:__ Оцінити асимптотичну складність алгоритму лінійного пошуку у $О$-нотації."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Асимптотична складність алгоритму лінійного пошуку у O-нотації - O(n), де \"n\" - розмір вхідного списку \"a_list\".\n",
    "\n",
    "У найгіршому випадку, коли шуканий елемент не знаходиться в списку, алгоритм повинен перевірити всі n елементів, щоб зрозуміти, що елемент не присутній. Тому, кількість операцій, яку необхідно виконати, зростає пропорційно розміру списку.\n",
    "\n",
    "Отже, асимптотична складність лінійного пошуку у найгіршому випадку становить O(n)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Завдання на самостійну роботу__:\n",
    "\n",
    "* Оцінити асимптотичну складність алгоритму бінарного пошуку пошуку у $О$-нотації.\n",
    "Алгоритм бінарного пошуку є більш ефективним алгоритмом пошуку, ніж алгоритм лінійного пошуку. Він працює шляхом багаторазового ділення інтервалу пошуку навпіл, усуваючи половину, в якій не може бути потрібний елемент, доки елемент не буде знайдено або інтервал пошуку не стане порожнім.\n",
    "\n",
    "Найгірша часова складність алгоритму бінарного пошуку дорівнює O(log n), де n — кількість елементів у відсортованому списку, який шукається. Це означає, що час роботи алгоритму зростає логарифмічно із розміром вхідних даних.\n",
    "\n",
    "Іншими словами, якщо ми подвоїмо розмір списку, алгоритм зробить ще один крок, щоб знайти елемент. Це значне покращення порівняно з лінійним пошуком, особливо для великих списків.\n",
    "\n",
    "\n",
    "\n",
    "* написати функцію, яка б могла повертати датафрейм з наступним складом полів: (\"n\", \"time\"), де `n` -- розмір масиву для функції `linear_searh();\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def linear_search(data_size):\n",
    "    # perform linear search on an array of size data_size\n",
    "    arr = list(range(data_size))\n",
    "    key = data_size - 1\n",
    "    start_time = time.time()\n",
    "    found = False\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i] == key:\n",
    "            found = True\n",
    "            break\n",
    "    end_time = time.time()\n",
    "    search_time = end_time - start_time\n",
    "    return (data_size, search_time)\n",
    "\n",
    "def generate_dataframe(min_size, max_size, step_size):\n",
    "    data = []\n",
    "    for size in range(min_size, max_size + 1, step_size):\n",
    "        result = linear_search(size)\n",
    "        data.append(result)\n",
    "    df = pd.DataFrame(data, columns=[\"n\", \"time\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "* написати функцію, яка б могла повертати датафрейм з наступним складом полів: (\"n\", \"time\"), де `n` -- розмір масиву для функції `bin_searh();\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def binary_search_time(n):\n",
    "    arr = np.arange(n)\n",
    "    target = np.random.randint(n)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    index = np.searchsorted(arr, target, 'left')\n",
    "    end_time = time.time()\n",
    "    \n",
    "    search_time = end_time - start_time\n",
    "    \n",
    "    return pd.DataFrame({\"n\": [n], \"time\": [search_time]})\n",
    "\n",
    "* за результатами попередніх завдань побудувати графіки залежності часу виконання процедури пошуку від розміру масиву. Приклад побудови графіків у середовищі `Ipython` можна подивитися [тут](https://devpractice.ru/python-lesson-6-work-in-jupyter-notebook/).  \n",
    "\n",
    "\n",
    "* оцінити, який з двох алгоритмів є більш ефективним та в якому діапазоні розміру задачі.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def linear_search(arr, target):\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i] == target:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def binary_search(arr, target):\n",
    "    left, right = 0, len(arr) - 1\n",
    "    while left <= right:\n",
    "        mid = (left + right) // 2\n",
    "        if arr[mid] == target:\n",
    "            return mid\n",
    "        elif arr[mid] < target:\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1\n",
    "    return -1\n",
    "\n",
    "def time_comparison():\n",
    "    # Set up array sizes to test\n",
    "    sizes = np.logspace(1, 5, num=20, dtype=int)\n",
    "    linear_times, binary_times = [], []\n",
    "\n",
    "    # Test each size with both algorithms\n",
    "    for n in sizes:\n",
    "        arr = np.arange(n)\n",
    "        target = np.random.randint(n)\n",
    "\n",
    "        start_time = time.time()\n",
    "        linear_search(arr, target)\n",
    "        linear_times.append(time.time() - start_time)\n",
    "\n",
    "        start_time = time.time()\n",
    "        binary_search(arr, target)\n",
    "        binary_times.append(time.time() - start_time)\n",
    "\n",
    "    # Plot the results\n",
    "    plt.plot(sizes, linear_times, label='Linear Search')\n",
    "    plt.plot(sizes, binary_times, label='Binary Search')\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Array Size (log scale)')\n",
    "    plt.ylabel('Time (log scale)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "time_comparison()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Під час виконання цього коду отриманий графік показуватиме час, витрачений обома алгоритмами, як функцію розміру масиву. Якщо двійковий пошук ефективніший, його лінія матиме менший нахил ніж лінія для лінійного пошуку, що вказує на те, що для пошуку великих масивів потрібно менше часу. Якщо лінійний пошук ефективніший, його лінія матиме менший нахил ніж лінія для бінарного пошуку. Діапазон розмірів проблеми, де один алгоритм ефективніший за інший. Залежатиме від конкретної реалізації та використовуваної машини, але загалом очікується, що бінарний пошук буде більш ефективним для великих масивів. Тоді як лінійний пошук може бути ефективнішим для малих масивів."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Контрольні запитання.\n",
    "\n",
    "1. Дати визначення складності задачі з символом $\\Omega$.\n",
    "\n",
    "1. Функція часової складності має вигляд: $F(N)=N^3+7N^2-14N$. Як записати асимптотичну складність в нотації $O()$?\n",
    "\n",
    "1. Функція часової складності має вигляд: $F(N)=1.01^N+N^{10}$. Як записати аисмптотичну складність в нотації $O()$?\n",
    "\n",
    "1. Функція часової складності має вигляд: $F(N)=N^{1.3}+10log_2N$. Як записати аисмптотичну складність в нотації $O()$?\n",
    "\n",
    "1. У чому полягає ідея розпараллелювання обчислень і для чого вона використовується? Які з алгоритмів, наведених у даній лаораторній роботі дозволяють можливість розпаралелювання?\n",
    "\n",
    "1. Які існують шляхи підвищення обчислювальної швидкості алгоритмів? Який з них є найбільш ефективним?\n",
    "\n",
    "\n",
    "\n",
    "1. Дати визначення складності задачі з символом $\\Omega$.\n",
    "Символ $\\Omega$ в теорії складності алгоритмів використовується для позначення нижньої межі складності задачі. Конкретніше, якщо функція f(n) є нижньою межею часу (або простору) для розв'язання задачі розміру n, то ми позначаємо це як f(n) = $\\Omega$(g(n)), де g(n) є будь-якою функцією, яка зростає не повільніше за$ f(n)$. Іншими словами, якщо задача має складність $\\Omega$(g(n)), то жоден алгоритм не може розв'язати її швидше, ніж за g(n) часу (або простору).\n",
    "\n",
    "\n",
    "2. Функція часової складності має вигляд: $F(N)=N^3+7N^2-14N$. Як записати аисмптотичну складність в нотації $O()$?\n",
    "Для визначення асимптотичної складності функції часу, ми повинні знайти найбільший член в цій функції. У даному випадку, найбільший член має степінь 3, тому ми можемо записати асимптотичну складність у нотації $𝑂(𝑁^3)$. Таким чином, функція часової складності 𝐹(𝑁) має асимптотичну складність $𝑂(𝑁^3)$.\n",
    "\n",
    "3. Функція часової складності має вигляд: $F(N)=1.01^N+N^{10}$. Як записати аисмптотичну складність в нотації $O()$?\n",
    "У даному випадку, найбільший член має степінь 10, але перший член також дуже швидко зростає зі збільшенням N. Тому, щоб точно визначити асимптотичну складність, потрібно порівняти обидва члени функції.\n",
    "\n",
    "4. Функція часової складності має вигляд: $F(N)=N^{1.3}+10log_2N$. Як записати аисмптотичну складність в нотації $O()$?\n",
    "Щоб записати асимптотичну складність в нотації O(), необхідно визначити домінуючий член у функції. Домінуючий член - це член з найбільшим порядком зростання при збільшенні значення N. У вашому випадку, ми маємо:\n",
    "\n",
    "$F(N) = N^{1.3} + 10log_2N$\n",
    "\n",
    "Коли N зростає до нескінченності, другий член стає менш значущим порівняно з першим членом, оскільки логарифмічна функція зростає повільніше, ніж будь-яка степінь. Тому домінуючим членом є $N^{1.3}$.\n",
    "\n",
    "\n",
    "5. У чому полягає ідея розпараллелювання обчислень і для чого вона використовується? Які з алгоритмів, наведених у даній лаораторній роботі дозволяють можливість розпаралелювання?\n",
    "Ідея розпаралелювання обчислень полягає в тому, щоб розбити велику задачу на менші підзадачі та виконувати їх одночасно на кількох обчислювальних пристроях (процесорах, ядрах, вузлах мережі тощо) з метою скорочення часу виконання всієї задачі. Розпаралелювання може бути використане для різноманітних задач, таких як обчислення математичних функцій, симуляція фізичних систем, обробка великих об'ємів даних, машинне навчання та багато іншого.\n",
    "\n",
    "Merge Sort - цей алгоритм може бути легко розпаралелений шляхом розбиття вихідного масиву на менші підмасиви, які можна сортувати окремо, а потім об'єднати їх відсортований вихідний масив.\n",
    "\n",
    "6. Які існують шляхи підвищення обчислювальної швидкості алгоритмів? Який з них є найбільш ефективним?\n",
    "Існує безліч шляхів підвищення обчислювальної швидкості алгоритмів. Деякі з найбільш поширених шляхів:\n",
    "\n",
    "- Використання оптимізованих алгоритмів - створення алгоритмів, які працюють швидше і ефективніше за інші.\n",
    "\n",
    "- Розпаралелювання - використання можливості одночасного виконання операцій на багатьох процесорах або обчислювальних вузлах.\n",
    "\n",
    "- Кешування - використання кеш-пам'яті для зберігання результатів попередніх обчислень і зменшення кількості повторних обчислень.\n",
    "\n",
    "- Використання ефективних структур даних - використання оптимальних структур даних для зберігання і обробки даних.\n",
    "\n",
    "- Використання спеціалізованих обчислювальних пристроїв - використання спеціалізованих обчислювальних пристроїв, таких як графічні процесори (GPU) або тензорні пристрої для виконання специфічних операцій.\n",
    "\n",
    "- Мінімізація використання пам'яті - зменшення використання пам'яті алгоритмом, наприклад, використання ітераційних алгоритмів замість рекурсивних.\n",
    "\n",
    "- Найбільш ефективний шлях підвищення обчислювальної швидкості алгоритмів залежить від конкретної ситуації та вимог до алгоритму. У багатьох випадках оптимальний результат можна досягнути за допомогою комбінації кількох методів, а не одного.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
